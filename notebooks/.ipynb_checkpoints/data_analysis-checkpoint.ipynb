{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2cd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Timestamp\n",
    "from pandas.tseries.offsets import BDay\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf642a0",
   "metadata": {},
   "source": [
    "# 1. Change directory to raw data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9708a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Get the parent directory by going one level up\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Get the path of raw data folder\n",
    "data_raw_folder = os.path.join(parent_directory, 'data/raw')\n",
    "\n",
    "# Change the current working directory to raw data folder\n",
    "os.chdir(data_raw_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b7673",
   "metadata": {},
   "source": [
    "# 2. Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5eff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New issues data\n",
    "new_issues = pd.read_csv('new_issues.csv', index_col=0)\n",
    "new_issues_characteristics =  pd.read_csv('new_issues_characteristics.csv', index_col=0)\n",
    "new_issues_prices_refinitive_ask =  pd.read_csv('new_issues_prices_askyield_refinitive.csv', index_col=0)\n",
    "swap_rates = pd.read_csv('swap_rates.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc08c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparable bonds data\n",
    "chunk_dfs = []\n",
    "for i in range(6):\n",
    "    chunk_df = pd.read_csv(f'comparable_bonds_peers_duration_iboxx_{i+1}.csv', index_col=0)\n",
    "    chunk_dfs.append(chunk_df)\n",
    "\n",
    "comparable_bonds_iboxx = pd.concat(chunk_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f847fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index data\n",
    "iboxx_indices = pd.read_csv('iboxx_indices.csv', sep=';')\n",
    "move_index = pd.read_csv('move_index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a7b0d",
   "metadata": {},
   "source": [
    "# 3. Modify raw datasets and create subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c4123",
   "metadata": {},
   "source": [
    "## 3.1 New issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947330e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new issues dataframe with selected columns\n",
    "new_issues_sliced = new_issues.loc[:,['securities_isin', 'ticker', 'dealDate',\n",
    "                                      'issuerType', 'paymentType', 'countryName', 'COUNTRY_ISO_CODE', \n",
    "                                      'moodys', 'sp', 'fitch', 'expectedSize', 'actualSize', 'minimumDenomination', \n",
    "                                      'securityType', 'maturityTerm', 'coupon', 'seniority_name_1', \n",
    "                                      'seniority_name_1_adj', 'esgType', 'referenceType', 'ipt_reference',\n",
    "                                      'ipt_price_down', 'ipt_price_up', 'guidance_reference', 'guidance_price_down',\n",
    "                                      'guidance_price_up', 'launchValue', 'reofferValue', 'yieldToMaturity', 'duration',\n",
    "                                     'Industry_Group', 'Industry_Sector']]\n",
    "\n",
    "# Change time type\n",
    "new_issues_sliced['dealDate'] = pd.to_datetime(new_issues_sliced['dealDate'])\n",
    "new_issues_sliced['dealDate'] = new_issues_sliced['dealDate'].dt.floor('d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559481cc",
   "metadata": {},
   "source": [
    "## 3.2 Comparable bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time type\n",
    "comparable_bonds_iboxx['date'] = pd.to_datetime(comparable_bonds_iboxx['date'])\n",
    "comparable_bonds_iboxx['date'] = comparable_bonds_iboxx['date'].dt.floor('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9095273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "comparable_bonds_iboxx = comparable_bonds_iboxx.rename(columns={'new_issue_isin': 'isin', 'ticker': 'tickerCompBond'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec452e50",
   "metadata": {},
   "source": [
    "## 3.3 New issues characteristics; New issues prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc637a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new issues with corresponding payment ranks\n",
    "new_issues_sliced = new_issues_sliced.merge(new_issues_characteristics, left_on = 'securities_isin', right_on = 'security', how = 'inner')\n",
    "new_issues_sliced = new_issues_sliced.drop(['security'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b157855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time type in refinitive prices dataset\n",
    "new_issues_prices_refinitive_ask['Date'] = pd.to_datetime(new_issues_prices_refinitive_ask['Date'])\n",
    "new_issues_prices_refinitive_ask['Date'] = new_issues_prices_refinitive_ask['Date'].dt.date\n",
    "new_issues_prices_refinitive_ask['Date'] = new_issues_prices_refinitive_ask['Date'].astype('datetime64')\n",
    "new_issues_prices_refinitive_ask['Date'] = new_issues_prices_refinitive_ask['Date'].dt.floor('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1603f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'wrong' prices (EUR price instead of yield)\n",
    "new_issues_prices_refinitive = new_issues_prices_refinitive_ask[(abs(new_issues_prices_refinitive_ask['Ask Yield']) < 10) | (new_issues_prices_refinitive_ask['Ask Yield'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77ef6c",
   "metadata": {},
   "source": [
    "## 3.4 Iboxx indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef34175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time type in iboxx index dataset\n",
    "iboxx_indices['Download_Date'] = pd.to_datetime(iboxx_indices['Download_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d3282f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create issue dataframe with selected columns\n",
    "iboxx_indices_sliced = iboxx_indices.loc[:,['Download_Date', 'Name', 'Annual_Yield_to_Maturity', 'Expected_Remaining_Life']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d80752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only iBoxx € Corporates Senior and iBoxx € Financials Senior\n",
    "iboxx_indices_sliced = iboxx_indices_sliced[iboxx_indices_sliced['Name'].isin(['iBoxx € Corporates Senior', 'iBoxx € Financials Senior'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f8961",
   "metadata": {},
   "source": [
    "## 3.5 Swap rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96fb3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column names and their corresponding years\n",
    "columns = swap_rates.columns\n",
    "years = []\n",
    "\n",
    "# Determine if the column represents months or years and extract the corresponding number\n",
    "for col in columns:\n",
    "    match = re.search(r'(\\d+)([YM])=', col)\n",
    "    if match:\n",
    "        num = int(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        if unit == 'Y':\n",
    "            years.append(num)\n",
    "        elif unit == 'M':\n",
    "            years.append(num / 12)\n",
    "            \n",
    "# Create a dictionary to map the old column names to the new column names\n",
    "new_columns = {col: yr for col, yr in zip(columns, years)}\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "swap_rates.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "# Sort the columns in ascending order\n",
    "swap_rates = swap_rates.reindex(sorted(swap_rates.columns), axis=1)\n",
    "\n",
    "# Change time type in refinitive prices dataset\n",
    "swap_rates = swap_rates.reset_index()\n",
    "swap_rates['Date'] = pd.to_datetime(swap_rates['Date'])\n",
    "swap_rates['Date'] = swap_rates['Date'].dt.date\n",
    "swap_rates['Date'] = swap_rates['Date'].astype('datetime64')\n",
    "swap_rates['Date'] = swap_rates['Date'].dt.floor('d')\n",
    "swap_rates = swap_rates.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68a71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the maturities from column names\n",
    "maturities = [col for col in swap_rates.columns]\n",
    "\n",
    "# Interpolate the swap rate curve for each timestamp\n",
    "interpolated_swap_rates = {}\n",
    "for timestamp, row in swap_rates.iterrows():\n",
    "    swap_rate_interpolator = interp1d(maturities, row, kind='cubic')\n",
    "    interpolated_swap_rates[timestamp] = swap_rate_interpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203ed9c",
   "metadata": {},
   "source": [
    "# 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687f4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                      2017    2018    2019    2020    2021    2022    2023\n",
      "Financial               55.74%  65.75%  64.52%  49.09%  61.14%  68.07%  67.31%\n",
      "Utilities                 8.2%  10.27%   7.62%   12.2%  11.14%  10.26%   10.9%\n",
      "Consumer, Non-cyclical   6.56%    8.9%   9.38%   12.8%   10.6%   6.29%   8.33%\n",
      "Consumer, Cyclical       4.92%   7.53%   4.69%    6.4%   6.25%   5.83%   5.13%\n",
      "Communications          11.48%   2.74%   7.33%   4.57%   2.72%    2.1%   1.92%\n",
      "Secured                 32.79%   41.1%  28.74%   18.9%   23.1%  37.53%   39.1%\n",
      "Sr Preferred              nan%   6.85%  10.26%   7.32%  11.14%  11.19%   8.97%\n",
      "Sr Non Preferred         4.92%   6.85%  12.32%   8.54%   8.42%   6.06%   10.9%\n",
      "Sr Unsecured             62.3%  45.21%  48.68%  65.24%  57.34%  45.22%  41.03%\n",
      "0                        61.00  146.00  341.00  328.00  368.00  429.00  156.00\n",
      "coupon                    1.04    1.04    0.66    0.88    0.40    2.27    3.72\n",
      "maturityTerm              9.30    7.58    7.74    7.51    7.69    5.97    6.06\n",
      "AMT_ISSUED              756.64  769.72  768.93  741.60  695.38  787.96  798.40\n",
      "MIN_INCREMENT            43.20   48.12   44.26   50.80   40.82   48.08   47.96\n",
      "duration                  8.77    7.21    7.42    7.23    7.49    5.54    5.35\n"
     ]
    }
   ],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Extract year from dealDate\n",
    "new_issues_sliced['year'] = pd.to_datetime(new_issues_sliced['dealDate']).dt.year\n",
    "\n",
    "# Define the desired order of payment ranks\n",
    "payment_rank_order = ['Secured', 'Sr Preferred', 'Sr Non Preferred', 'Sr Unsecured']\n",
    "\n",
    "# Group by year and Industry_Sector, calculate average percentage and total number of bonds\n",
    "grouped = new_issues_sliced.groupby(['year', 'Industry_Sector']).size().unstack()\n",
    "distribution = grouped.div(grouped.sum(axis=1), axis=0) * 100\n",
    "average_percentage = distribution.mean()\n",
    "total_bonds = grouped.sum(axis=1)\n",
    "\n",
    "# Get the top 5 sectors based on highest average percentage\n",
    "top_sectors = average_percentage.nlargest(5).index.tolist()\n",
    "\n",
    "# Group by year and PAYMENT_RANK, calculate percentage distribution\n",
    "grouped_rank = new_issues_sliced.groupby(['year', 'PAYMENT_RANK']).size().unstack()\n",
    "distribution_rank = grouped_rank.div(grouped_rank.sum(axis=1), axis=0) * 100\n",
    "distribution_rank = distribution_rank[payment_rank_order].round(2).astype(str) + '%'\n",
    "\n",
    "# Filter the distribution and averages dataframes based on the top sectors\n",
    "filtered_distribution = distribution[top_sectors]\n",
    "filtered_distribution = filtered_distribution.round(2).astype(str) + '%'\n",
    "\n",
    "filtered_averages = new_issues_sliced.groupby('year').agg({'coupon': 'mean', 'maturityTerm': 'mean',\n",
    "                                                            'AMT_ISSUED': 'mean', 'MIN_INCREMENT': 'mean',\n",
    "                                                          'duration': 'mean'})\n",
    "\n",
    "# Divide AMT_ISSUED column by 1 million\n",
    "filtered_averages['AMT_ISSUED'] /= 1000000\n",
    "\n",
    "# Divide MIN_INCREMENT column by 1000\n",
    "filtered_averages['MIN_INCREMENT'] /= 1000\n",
    "\n",
    "# Merge the filtered distribution, total bonds, and averages dataframes\n",
    "table = pd.concat([filtered_distribution, distribution_rank, total_bonds, filtered_averages], axis=1)\n",
    "\n",
    "# Transpose the table\n",
    "table = table.transpose()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "table.columns = table.columns.astype(str)\n",
    "\n",
    "# Print the table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d6efd",
   "metadata": {},
   "source": [
    "## 3.6 Create dataframe of initial MS of new issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS spread from IPREO data\n",
    "new_issues_yield_ipreo = new_issues_sliced.loc[:, ['dealDate', 'securities_isin', 'ticker', 'maturityTerm', 'duration', 'PAYMENT_RANK', 'issuerType', 'reofferValue']]\n",
    "new_issues_yield_ipreo = new_issues_yield_ipreo.rename(columns={'securities_isin': 'isin'})\n",
    "new_issues_yield_ipreo = new_issues_yield_ipreo.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f87e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep new issues with known initial MS\n",
    "new_issues_initial_prices = new_issues_yield_ipreo.loc[~new_issues_yield_ipreo['reofferValue'].isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e76b5230",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_issues_initial_prices = new_issues_initial_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813e0cc",
   "metadata": {},
   "source": [
    "## 3.7 Find comparable bonds at the day of the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163806fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge comparable bonds on 'ticker' and 'dealDate' columns\n",
    "new_issues_with_comp = new_issues_initial_prices.merge(comparable_bonds_iboxx, left_on=['isin', 'dealDate'], right_on=['isin', 'date'], how='inner')\n",
    "new_issues_with_comp = new_issues_with_comp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbe831b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep comparable bonds with the same payment rank\n",
    "new_issues_with_comp = new_issues_with_comp[new_issues_with_comp['PAYMENT_RANK']==new_issues_with_comp['Payment_Rank']]\n",
    "new_issues_with_comp = new_issues_with_comp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18aa809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_issues_with_comp_filtered[['dealDate', 'ISIN']].drop_duplicates().to_csv('comparable_bonds_peers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "555865f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maturity difference\n",
    "new_issues_with_comp['duration_diff'] = new_issues_with_comp['duration'] - new_issues_with_comp['Duration']\n",
    "new_issues_with_comp['maturity_diff'] = new_issues_with_comp['maturityTerm'] - new_issues_with_comp['Time_To_Maturity']\n",
    "new_issues_with_comp['maturity_diff_abs'] = abs(new_issues_with_comp['maturityTerm'] - new_issues_with_comp['Time_To_Maturity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a62db65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep bonds with close maturities (difference < 1 year)\n",
    "new_issues_with_comp_filtered = new_issues_with_comp.loc[new_issues_with_comp['maturity_diff_abs'] <= 0.5]\n",
    "new_issues_with_comp_filtered = new_issues_with_comp_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7690408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           2017  2018  2019  2020  2021  2022  2023\n",
      "Average                    5.39  7.33  8.27  6.27  7.02 13.48 16.38\n",
      "Average_Same_Tickers       0.18  0.22  0.26  0.35  0.27  0.53  0.56\n",
      "Average_Diff_Tickers       5.21  7.11  8.01  5.91  6.75 12.95 15.81\n",
      "Average_Duration           0.27  0.08  0.21  0.18  0.21 -0.19 -0.35\n",
      "Average_Maturity_Diff_Abs  0.07  0.04  0.08  0.05  0.05  0.02  0.03\n"
     ]
    }
   ],
   "source": [
    "# Convert 'dealDate' to datetime type\n",
    "new_issues_with_comp_filtered['dealDate'] = pd.to_datetime(new_issues_with_comp_filtered['dealDate'])\n",
    "\n",
    "# Extract year from 'dealDate'\n",
    "new_issues_with_comp_filtered['year'] = new_issues_with_comp_filtered['dealDate'].dt.year\n",
    "\n",
    "# Group by 'year', 'isin', and calculate count, average duration, and average maturity_diff_abs for each group\n",
    "grouped_data_all = new_issues_with_comp_filtered.groupby(['year', 'isin']).agg({\n",
    "    'ticker': 'count',  # Rename 'count' to 'ticker'\n",
    "    'duration_diff': 'mean',\n",
    "    'maturity_diff': 'mean'\n",
    "}).reset_index()\n",
    "grouped_data_all.rename(columns={'ticker': 'count'}, inplace=True)  # Rename the 'ticker' column back to 'count'\n",
    "\n",
    "# Calculate the average count of matched bonds for each year\n",
    "average_count_per_year = grouped_data_all.groupby('year')['count'].mean().reset_index()\n",
    "average_count_per_year.rename(columns={'count': 'Average_Count'}, inplace=True)\n",
    "\n",
    "# Create dummy columns to indicate if 'ticker' and 'tickerCompBond' are the same or not\n",
    "new_issues_with_comp_filtered['same_ticker'] = new_issues_with_comp_filtered['ticker'] == new_issues_with_comp_filtered['tickerCompBond']\n",
    "\n",
    "# Group by 'year', 'isin', and the dummy column, and calculate sum for each group\n",
    "grouped_data = new_issues_with_comp_filtered.groupby(['year', 'isin', 'same_ticker']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total count of matched bonds for each year\n",
    "total_count_per_year = grouped_data.groupby('year')['count'].sum().reset_index()\n",
    "\n",
    "# Calculate the number of unique ISINs for each year\n",
    "unique_isins_per_year = grouped_data.groupby('year')['isin'].nunique().reset_index()\n",
    "\n",
    "# Calculate the average count of matched bonds per ISIN for each year with the same and different tickers\n",
    "average_count_per_year_same = grouped_data[grouped_data['same_ticker'] == True].groupby('year')['count'].sum().reset_index()\n",
    "average_count_per_year_same['count'] /= unique_isins_per_year['isin']\n",
    "average_count_per_year_same.rename(columns={'count': 'Average_Same_Tickers'}, inplace=True)\n",
    "\n",
    "average_count_per_year_not_same = grouped_data[grouped_data['same_ticker'] == False].groupby('year')['count'].sum().reset_index()\n",
    "average_count_per_year_not_same['count'] /= unique_isins_per_year['isin']\n",
    "average_count_per_year_not_same.rename(columns={'count': 'Average_Diff_Tickers'}, inplace=True)\n",
    "\n",
    "# Calculate the average duration for each year, grouped by ISINs\n",
    "average_duration_per_year = grouped_data_all.groupby('year')['duration_diff'].mean().reset_index()\n",
    "average_duration_per_year.rename(columns={'duration_diff': 'Average_Duration'}, inplace=True)\n",
    "\n",
    "# Calculate the average maturity_diff_abs for each year, grouped by ISINs\n",
    "average_maturity_diff_abs_per_year = grouped_data_all.groupby('year')['maturity_diff'].mean().reset_index()\n",
    "average_maturity_diff_abs_per_year.rename(columns={'maturity_diff': 'Average_Maturity_Diff_Abs'}, inplace=True)\n",
    "\n",
    "# Create DataFrames with the average counts for each year\n",
    "average_count_per_year_summary = average_count_per_year.set_index('year').transpose().reset_index(drop=True)\n",
    "average_count_per_year_summary.columns.name = None  # Remove the index name\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "result_df = pd.concat([\n",
    "    average_count_per_year_summary,\n",
    "    average_count_per_year_same.set_index('year').transpose(),\n",
    "    average_count_per_year_not_same.set_index('year').transpose(),\n",
    "    average_duration_per_year.set_index('year').transpose(),\n",
    "    average_maturity_diff_abs_per_year.set_index('year').transpose()\n",
    "], axis=0)\n",
    "\n",
    "# Rename the index names for clarity\n",
    "result_df.rename(index={0: 'Average'}, inplace=True)\n",
    "\n",
    "# Display the final DataFrame with 5 rows and years as columns\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5570e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nip_env",
   "language": "python",
   "name": "nip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
